# -*- coding: utf-8 -*-
"""PRO A Phyton

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Re7d8HJFEaVTcfdM5mEoEyIigXHhtca4
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

medium_data = pd.read_csv('drive/MyDrive/PRO A/phyton/medium_data.csv',parse_dates= ['date'],dayfirst=True)

no_id = medium_data
df = no_id[['date','publication','title','subtitle','reading_time','responses','claps','url']].copy()
df.head(2)

"""Clearing Data Proses"""

#Data Cleaning (Fill NaN)
df['subtitle'].fillna('blank subtitles',inplace = True)
df['claps'].fillna(0,inplace = True)

#Output Test
# df

#setting data type in DataFrame
df['title'] = df['title'].astype('string')
df['subtitle'] = df['subtitle'].astype('string')
df['claps'] = df['claps'].astype('int')

#check NaN or nul in dataFrame
df['claps'].isnull().value_counts()

#Check Duplicate
check_duplicate = df[df.duplicated()]

#Remove Duplicate
df.drop_duplicates(subset =['date','publication','title','subtitle','reading_time','responses','claps','url'], inplace = True)

#Output Test
# df

import re

#Data Cleaning (clear symbol and other)
collect_title = []
collect_subtitle = []

for i in df['title']:
  new_title = re.sub(r"<(.*?)>","",i)
  collect_title.append(new_title)

for j in df['subtitle']:
  new_subtitle = re.sub(r"<(.*?)>","",j)
  collect_subtitle.append(new_subtitle)

df['title'] = collect_title
df['subtitle'] = collect_subtitle

#output test
# df

#save file
save  = df
save.to_csv('medium_data_clear.csv')

"""Text Processing with NLTK"""

import nltk 
nltk.download('all')

#collect title
medium_data = df[['date','publication','title','subtitle','reading_time','responses','claps']]

all_title ='*'
for i in medium_data['title']:
  all_title += i + ' '

#output
print(all_title)

#case folding
import re
import string

sub_sentence = re.sub(r"<(.*?)>"," ",all_title) #menghilangkan karakter yang berawalan < dan berakhiran > 
lower_title=sub_sentence.lower() #membuat lower
remove_punctuationmark = lower_title.translate(str.maketrans("","",string.punctuation)) #menghilangkan tanda baca selian "-
sub_number = re.sub(r"\d+","",lower_title) #menghilangkan angka
sub_notword = re.sub(r"\W"," ",sub_number) #menghilangkan karakter lain selian huruf
sub_doublespace = re.sub(r"\s+"," ",sub_notword ) #menghilangkan spasi double

#Output
print(sub_doublespace)

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

#Tokenizing 
tokens = nltk.word_tokenize(sub_doublespace)

#Filtering (Stopword Removal)
liststopwords = stopwords.words('english')

word_filter = []
for w in tokens:
  if w not in liststopwords:
    word_filter.append(w)

#output
print(tokens)
print(word_filter)

from nltk.stem import WordNetLemmatizer

#Steming Process
wnl = WordNetLemmatizer()

after_steming = []
for k in word_filter:
  after_steming.append(wnl.lemmatize(k))

#output
print(after_steming)
# for k in word_filter:
#   print(k, " : ", wnl.lemmatize(k))

from nltk.probability import FreqDist

#collect list count
word_freq = nltk.FreqDist(after_steming)

#output
print(word_freq.most_common())
plt.figure(figsize=(14,5))
word_freq.plot(70,cumulative=False)

import pandas as pd
import matplotlib.pyplot as plt

#convert frequence to Dataframe
freg_word = pd.DataFrame.from_dict(word_freq,orient='index')
freg_word.columns = ['Title']
freg_word.index.name = 'Kata'

freg_word = freg_word.sort_values(by =['Title'], ascending=False)

#visualization & Output
ax = freg_word.head(10).plot.bar()
ax.bar_label(ax.containers[0]) #anotate bar
plt.title('''
  Tren Kata Kunci dalam Judul Artikel 
  di Platform Medium Bulan Januari-Maret 2023
  ''')
plt.ylabel('Frekuensi')

"""Popular Articel"""

#Readingtime view
df3=df[['date','publication','title','reading_time','responses','claps']]

readingtime_view =df3.sort_values(by =['reading_time'], ascending=False)
readingtime_view.head()

#claps view
claps_view =df3.sort_values(by =['claps'], ascending=False)
claps_view.head(5)

#date view
date_upload=df3.sort_values(by =['date'], ascending=True)
date_upload

"""Perbandingan Intensitas Upload Artikel untuk Setiap Penerbit"""

date_upload['publication'].unique()

#Article Upload Corp 1
corp_1 = date_upload[date_upload['publication']=='The Writing Cooperative'].copy()
corp_1['article_count_corp_1'] = 1
corp_1 = corp_1[['date','article_count_corp_1']]

#Data Upload record
record_upload_corp_1 = corp_1.groupby(['date']).count()
c1 = record_upload_corp_1

#output test
# corp_1.head(2)
# c1

#Article Upload Corp 2
corp_2 = date_upload[date_upload['publication']=='The Startup'].copy()
corp_2['article_count_corp_2'] = 1
corp_2 = corp_2[['date','article_count_corp_2']]
record_upload_corp_2 = corp_2.groupby(['date']).count()
c2 = record_upload_corp_2

#Article Upload Corp 3
corp_3 = date_upload[date_upload['publication']=='Towards Data Science'].copy()
corp_3['article_count_corp_3'] = 1
corp_3 = corp_3[['date','article_count_corp_3']]
record_upload_corp_3 = corp_3.groupby(['date']).count()
c3 = record_upload_corp_3

#Article Upload Corp 4
corp_4 = date_upload[date_upload['publication']=='UX Collective'].copy()
corp_4['article_count_corp_4'] = 1
corp_4 = corp_4[['date','article_count_corp_4']]
record_upload_corp_4 = corp_4.groupby(['date']).count()
c4 = record_upload_corp_4

#Join c1,c2,c3,c4 
join_c1c2 = c1.set_index(c1.index).join(c2.set_index(c2.index),how='outer')
join_c3c4 = c3.set_index(c3.index).join(c4.set_index(c4.index),how='outer')

freg_upload = join_c1c2.set_index(join_c1c2.index).join(join_c3c4.set_index(join_c3c4.index), how = 'outer')

#output test
# join_c1c2.head(2)
# join_c3c4.head(2)
freg_upload.head()

#data cleaning
freg_upload.fillna(0,inplace=True)
freg_upload['article_count_corp_3'] = freg_upload['article_count_corp_3'].astype('int')
freg_upload['article_count_corp_4'] = freg_upload['article_count_corp_4'].astype('int')
freg_upload

import matplotlib.dates as mdates

time = freg_upload.index
pub_1 = freg_upload['article_count_corp_1']
pub_2 = freg_upload['article_count_corp_2']
pub_3 = freg_upload['article_count_corp_3']
pub_4 = freg_upload['article_count_corp_4']

locator = mdates.DayLocator(bymonthday=[1, 8, 15, 22])
formatter = mdates.DateFormatter('%d %b')

fig, ax = plt.subplots(figsize=(10, 6), tight_layout=True)
ax.xaxis.set_major_locator(locator)
ax.xaxis.set_major_formatter(formatter)
ax.tick_params(axis='x', rotation=0)
#set data
ax.plot(time, pub_1)
ax.plot(time, pub_2)
ax.plot(time, pub_3)
ax.plot(time, pub_4)

ax.grid(True)
ax.set_xlabel('Time')
ax.set_ylabel('Upload Frequency Article')
ax.legend(['The Writing Cooperative','The Startup','Towards Data Science','UX Collective'])
ax.set_title('''
Frekuensi Mengunggah Artikel 
Bulan Januari - April Tahun 2023
''')
plt.show()

"""Perbandingan antara readingtime, responses, dan claps"""

import matplotlib.pyplot as plt
import seaborn as sns

only_data = df[['publication','reading_time','responses','claps']]

#output
only_data

#visualisation
plt.figure(figsize=(14,5))
sns.boxplot(data=only_data, y='publication', x='reading_time')
plt.xlabel('Frekuensi Waktu Baca')
plt.ylabel('Publiser')
plt.title('''
Perbandingan Lama Waktu Baca Artikel Medium Tahun 2023 
''')

import matplotlib.pyplot as plt
import seaborn as sns

only_data = df[['publication','reading_time','responses','claps']]

#output
only_data

#visualisation
plt.figure(figsize=(14,5))
sns.boxplot(data=only_data, y='publication', x='responses')
plt.xlabel('Frekuensi Komentar')
plt.ylabel('Publiser')
plt.title('''
Perbandingan Jumlah Komentar Artikel Medium Tahun 2023 
''')

import matplotlib.pyplot as plt
import seaborn as sns

only_data = df[['publication','reading_time','responses','claps']]

#output
only_data

#visualisation
plt.figure(figsize=(14,5))
sns.boxplot(data=only_data, y='publication', x='claps')
plt.xlabel('Frekuensi Tepuk Tangan')
plt.ylabel('Publiser')
plt.title('''
Perbandingan Jumlah Tepuk Tangan Artikel Medium Tahun 2023 
''')

import matplotlib.pyplot as plt

article_count = df[['publication','title','subtitle']]

publiser = article_count.groupby(['publication']).count()

#output
print(publiser)
plt.barh(publiser.index,publiser['title'])
plt.tick_params(axis='x', rotation=90)
plt.xlabel('Frekuensi')
plt.ylabel('Publiser')
plt.title('''
Frekuensi Upload Artikel Tahun 2023 
''')